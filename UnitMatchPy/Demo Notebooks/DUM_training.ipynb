{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa23a02",
   "metadata": {},
   "source": [
    "## DeepUnitMatch training notebook\n",
    "\n",
    "This demo notebook will take you through training DeepUnitMatch on your own data. This is not necessary, as the neural network is able to generalise to unseen datasets, but training on your own data is very likely to improve performance.\n",
    "\n",
    "You should only proceed if you have a substantial amount of Neuropixels 2.0 data you wish to use for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'DeepUnitMatch'))\n",
    "from DeepUnitMatch.utils import AE_npdataset, npdataset\n",
    "from DeepUnitMatch.train.train_AE import run_training\n",
    "from DeepUnitMatch.train.train_finetune import run_finetune\n",
    "from DeepUnitMatch.utils import param_fun\n",
    "from DeepUnitMatch.testing import test\n",
    "import UnitMatchPy.default_params as default_params\n",
    "import UnitMatchPy.utils as util\n",
    "import matplotlib.pyplot as plt\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968a41b",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "You should have a list of Kilosort directories you want to use for training. If you have run Bombcell on this data (recommended) then these directories should also contain the bombcell results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data the same way as UnitMatch\n",
    "\n",
    "# Get default parameters, can add your own before or after!\n",
    "param = default_params.get_default_param()\n",
    "\n",
    "# Give the paths to the KS directories for each session\n",
    "# If you don't have a dir with channel_positions.npy etc look at the detailed example for supplying paths separately\n",
    "KS_dirs = [r'path/to/KSdir/Session1', r'path/to/KSdir/Session2', r'path/to/KSdir/Session3', r'path/to/KSdir/Session4']\n",
    "\n",
    "# KS_dirs should contain a large number of paths\n",
    "\n",
    "param['KS_dirs'] = KS_dirs\n",
    "wave_paths, unit_label_paths, channel_pos = util.paths_from_KS(KS_dirs)\n",
    "param = util.get_probe_geometry(channel_pos[0], param)\n",
    "\n",
    "# STEP 0 from the UMPy example notebook\n",
    "waveform, session_id, session_switch, within_session, good_units, param = util.load_good_waveforms(wave_paths, unit_label_paths, param, good_units_only = True)\n",
    "param['good_units'] = good_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6868c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"path/to/save_directory\"\n",
    "# This is where the waveform snippets used in DeepUnitMatch will be saved, under a folder called \"processed_waveforms\"\n",
    "# Make sure there is no existing data at save_path/processed_waveforms to avoid overwriting!\n",
    "\n",
    "snippets, positions = param_fun.get_snippets(waveform, channel_pos, session_id, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c744c",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Training takes place in two steps: autoencoder training and finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db61c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder pretraining\n",
    "\n",
    "EXPERIMENT_NAME = \"DeepUnitMatch_DEMO\"              # This is the name for the whole experiment (both training steps)\n",
    "\n",
    "AEdataset = AE_npdataset.AE_NeuropixelsDataset(save_path, batch_size=32)\n",
    "training_thread = threading.Thread(target=run_training, args=(EXPERIMENT_NAME, AEdataset), kwargs={'lr':1e-5, 'save_freq':1, 'total_epoch':3, 'cont':False, 'batchsize':32})        # recommend 300 epochs\n",
    "training_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive learning finetuning\n",
    "\n",
    "CLdataset = npdataset.NeuropixelsDataset(save_path, batch_size=32, mode='train')\n",
    "\n",
    "if training_thread is not None and training_thread.is_alive():\n",
    "    print(\"Wait for autoencoder training to finish...\")\n",
    "else:\n",
    "    training_thread = threading.Thread(target=run_finetune, args=(EXPERIMENT_NAME, CLdataset), kwargs={'lr_enc':2*1e-5, 'lr_proj': 1.1*1e-4, 'save_freq':1, 'total_epoch':3, 'cont':False, 'batchsize':32})         # recommend 50 epochs\n",
    "    training_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d40b8b8",
   "metadata": {},
   "source": [
    "### Load the trained model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = r\"path/to/your/saved/model/checkpoint\"  # Path to your trained model checkpoint\n",
    "\n",
    "model = test.load_trained_model(device=\"cpu\", read_path=read_path)\n",
    "sim_matrix = test.inference(model, os.path.join(save_path, 'processed_waveforms'))\n",
    "plt.imshow(sim_matrix, cmap='viridis', aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31043fa1",
   "metadata": {},
   "source": [
    "From here, you can follow the standard demo notebook to use your trained model in the full DeepUnitMatch pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UMPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
