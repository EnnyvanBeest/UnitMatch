{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa23a02",
   "metadata": {},
   "source": [
    "## DeepUnitMatch training notebook\n",
    "\n",
    "This demo notebook will take you through training DeepUnitMatch on your own data. This is not necessary, as the neural network is able to generalise to unseen datasets, but training on your own data is very likely to improve performance.       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from DeepUnitMatch.train import train_AE, train_finetune\n",
    "from DeepUnitMatch.utils import train_utils, AE_npdataset, npdataset, mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968a41b",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "In order to easily load your own Neuropixels 2.0 data into the neural network for training, there are custom pytorch datasets. These load data with a hierarchical structure:\n",
    "\n",
    "[ROOT]/[MOUSE]/[PROBE]/[LOCATION]/[EXPERIMENT]/processed_waveforms\n",
    "\n",
    "Each 'processed_waveforms' directory should contain the .npy files, one per waveform, each of shape (60, 30, 2) -- (timepoints, channels, session halves) \n",
    "\n",
    "Assuming you have a decent amount of data in this format, we can perform the two training steps of DeepUnitMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261d362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba8309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
