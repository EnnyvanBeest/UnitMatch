{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This demo notebook, is a detailed guide throught the Unit Match pipeline.\n",
    "\n",
    "This notebook is only recomened if you want more detailed look at Unit Match, or have unconventional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import UnitMatchPy.param_functions as pf\n",
    "import UnitMatchPy.metric_functions as mf\n",
    "import UnitMatchPy.bayes_functions as bf\n",
    "import UnitMatchPy.utils as util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import UnitMatchPy.GUI as gui\n",
    "import UnitMatchPy.save_utils as su\n",
    "import UnitMatchPy.assign_unique_id as aid\n",
    "import UnitMatchPy.default_params as default_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in necessary data, individually \n",
    "(Not recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can supply paths to files directly, but recommended to use the paths_fromKS function below\n",
    "#get default parameters, can add your own before or after!\n",
    "param = default_params.get_default_param()\n",
    "\n",
    "#Load in the data\n",
    "#The channel position i.e location of active channels\n",
    "channel_pos1 = np.load(r'Path\\to\\channel_positions.npy')\n",
    "#This makes position 3-D by inserting an axis of all one's in the first axis, to allow easy extension to 3-D coords\n",
    "channel_pos1 = np.insert(channel_pos1,0, np.ones(channel_pos1.shape[0]), axis =1)\n",
    "\n",
    "#path to the average waveforms for each session\n",
    "wave_path1 = r'Path\\to\\RawWaveforms'\n",
    "wave_path2 = r'Path\\to\\RawWaveforms'\n",
    "\n",
    "#path to a tsv file, where the second column contains 'good' for all units you want to include\n",
    "unit_label_path1 = r'Path\\to\\cluster_group.tsv'\n",
    "unit_label_path2 = r'Path\\to\\cluster_group.tsv'\n",
    "\n",
    "# need to put paths as a list\n",
    "wave_paths = [wave_path1 , wave_path2]\n",
    "unit_label_paths = [unit_label_path1, unit_label_path2]\n",
    "channel_pos = [channel_pos1, channel_pos1] # Want it per session, however usually will be the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from a KiloSort directory\n",
    "This directory needs to have a channel_positoins.npy, cluster_group.tsv and a RawWaveforms folder per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get default parameters, can add your own before or after!\n",
    "param = default_params.get_default_param()\n",
    "\n",
    "\n",
    "#Give the paths to the KS directories for each session (with a file 'RawWaveforms' )\n",
    "KS_dirs = [r'path/to/KSdir/Session1', r'Path/to/KSdir/Session2']\n",
    "#KS_dirs = [r'C:\\Users\\Experiment\\Data\\EB019-large data test\\2022-07-21', r'C:\\Users\\Experiment\\Data\\EB019-large data test\\2022-07-22']\n",
    "\n",
    "param['KS_dirs'] = KS_dirs\n",
    "wave_paths, unit_label_paths, channel_pos = util.paths_from_KS(KS_dirs)\n",
    "param = util.get_probe_geometry(channel_pos[0], param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data and select the good units and exact metadata\n",
    "\n",
    "good_units = util.get_good_units(unit_label_paths, good = True ) # good = False to load in ALL units\n",
    "waveform, session_id, session_switch, within_session, param = util.load_good_units(good_units, wave_paths, param)\n",
    "\n",
    "#waveform, session_id, session_switch, within_session, param = util.load_good_waveforms(wave_paths, unit_label_paths, param) # 1-step version of above\n",
    "\n",
    "# create clus_info, contains all unit id/session related info\n",
    "clus_info = {'good_units' : good_units, 'session_switch' : session_switch, 'session_id' : session_id, \n",
    "            'original_ids' : np.concatenate(good_units) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Unit Match process\n",
    "1. Extract parameters from the waveforms e.g Amplitudes, weighted average waveforms and Spatial Decay lengths\n",
    "2. Calculate metrics/scores for matching e.g Amplitude Score and Waveform similarity\n",
    "3. Using putative matches find a estimate of drit correction between session (canbe done per shank for 2.0 probes)\n",
    "4. Re-Calculate metrics/scores with the drift corrected metrics\n",
    "5. Use a naive Bayes classifier to get suggested 'matches' and 'non'matches'\n",
    "6. (Optionall) run the GUIto currated the suggest matches and investigated the UnitMatch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get parameters from the wavefunction\n",
    "\n",
    "waveform = pf.detrend_waveform(waveform)\n",
    "\n",
    "max_site, good_idx, good_pos, max_site_mean = pf.get_max_sites(waveform, channel_pos, clus_info, param)\n",
    "\n",
    "spatial_decay_fit , spatial_decay,  d_10, avg_centroid, avg_waveform, peak_time = pf.decay_and_average_waveform(waveform, channel_pos, good_idx, max_site, max_site_mean, clus_info, param)\n",
    "\n",
    "amplitude, waveform, avg_waveform = pf.get_amplitude_shift_waveform(waveform, avg_waveform, peak_time, param)\n",
    "\n",
    "waveform_duration, avg_waveform_per_tp, good_wave_idxs = pf.get_avg_waveform_per_tp(waveform, channel_pos, d_10, max_site_mean, amplitude, avg_waveform, clus_info, param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Metrics/Scores from the extracted parameters\n",
    "\n",
    "amp_score = mf.get_simple_metric(amplitude)\n",
    "spatial_decay_score = mf.get_simple_metric(spatial_decay)\n",
    "spatial_decay_fit_score = mf.get_simple_metric(spatial_decay_fit, outlier = True)\n",
    "wave_corr_score = mf.get_wave_corr(avg_waveform, param)\n",
    "wave_mse_score = mf.get_waveforms_mse(avg_waveform, param)\n",
    "\n",
    "avg_waveform_per_tp_flip = mf.flip_dim(avg_waveform_per_tp, param)\n",
    "euclid_dist = mf.get_Euclidean_dist(avg_waveform_per_tp_flip, param)\n",
    "\n",
    "centroid_dist, centroid_var = mf.centroid_metrics(euclid_dist, param)\n",
    "\n",
    "euclid_dist_rc = mf.get_recentered_euclidean_dist(avg_waveform_per_tp_flip, avg_centroid, param)\n",
    "\n",
    "centroid_dist_recentered = mf.recentered_metrics(euclid_dist_rc)\n",
    "traj_angle_score, traj_dist_score = mf.dist_angle(avg_waveform_per_tp_flip, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collate themetrics and find the putative matches\n",
    "# Average Euc Dist\n",
    "euclid_dist = np.nanmin(euclid_dist[:,param['peak_loc'] - param['waveidx'] == 0, :,:].squeeze(), axis = 1 )\n",
    "\n",
    "# TotalScore\n",
    "include_these_pairs = np.argwhere( euclid_dist < param['max_dist']) #array indices of pairs to include\n",
    "\n",
    "# Make a dictionary of score to include\n",
    "centroid_overlord_score = (centroid_dist_recentered + centroid_var) / 2\n",
    "waveform_score = (wave_corr_score + wave_mse_score) / 2\n",
    "trajectory_score = (traj_angle_score + traj_dist_score) / 2\n",
    "\n",
    "scores_to_include = {'amp_score' : amp_score, 'spatial_decay_score' : spatial_decay_score, 'centroid_overlord_score' : centroid_overlord_score,\n",
    "                'centroid_dist' : centroid_dist, 'waveform_score' : waveform_score, 'trajectory_score': trajectory_score }\n",
    "\n",
    "total_score, predictors = mf.get_total_score(scores_to_include, param)\n",
    "\n",
    "#Initial thresholding\n",
    "\n",
    "thrs_opt = mf.get_threshold(total_score, within_session, euclid_dist, param, is_first_pass = True)\n",
    "\n",
    "param['nExpectedMatches'] = np.sum( (total_score > thrs_opt).astype(int))\n",
    "prior_match = 1 - ( param['nExpectedMatches'] / len(include_these_pairs))\n",
    "candidate_pairs = total_score > thrs_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drift\n",
    "drifts, avg_centroid, avg_waveform_per_tp = mf.drift_n_sessions(candidate_pairs, session_switch, avg_centroid, avg_waveform_per_tp, total_score, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-do metric extraction with the drift corrected arrays\n",
    "\n",
    "avg_waveform_per_tp_flip = mf.flip_dim(avg_waveform_per_tp, param)\n",
    "euclid_dist = mf.get_Euclidean_dist(avg_waveform_per_tp_flip,param)\n",
    "\n",
    "centroid_dist, centroid_var = mf.centroid_metrics(euclid_dist, param)\n",
    "\n",
    "euclid_dist_rc = mf.get_recentered_euclidean_dist(avg_waveform_per_tp_flip, avg_centroid, param)\n",
    "\n",
    "centroid_dist_recentered = mf.recentered_metrics(euclid_dist_rc)\n",
    "traj_angle_score, traj_dist_score = mf.dist_angle(avg_waveform_per_tp_flip, param)\n",
    "\n",
    "# Average Euc Dist\n",
    "euclid_dist = np.nanmin(euclid_dist[:,param['peak_loc'] - param['waveidx'] == 0, :,:].squeeze(), axis = 1 )\n",
    "\n",
    "# TotalScore\n",
    "include_these_pairs = np.argwhere( euclid_dist < param['max_dist']) #array indices of pairs to include, in ML its IncludeThesePairs[:,1]\n",
    "include_these_pairs_idx = np.zeros_like(total_score)\n",
    "include_these_pairs_idx[euclid_dist < param['max_dist']] = 1 \n",
    "\n",
    "# Make a dictionary of score to include\n",
    "centroid_overlord_score = (centroid_dist_recentered + centroid_var) / 2\n",
    "waveform_score = (wave_corr_score + wave_mse_score) / 2\n",
    "trajectory_score = (traj_angle_score + traj_dist_score) / 2\n",
    "\n",
    "scores_to_include = {'amp_score' : amp_score, 'spatial_decay_score' : spatial_decay_score, 'centroid_overlord_score' : centroid_overlord_score,\n",
    "                'centroid_dist' : centroid_dist, 'waveform_score' : waveform_score, 'trajectory_score': trajectory_score }\n",
    "\n",
    "total_score, predictors = mf.get_total_score(scores_to_include, param)\n",
    "thrs_opt = mf.get_threshold(total_score, within_session, euclid_dist, param, is_first_pass = False)\n",
    "\n",
    "\n",
    "param['n_expected_matches'] = np.sum( (total_score > thrs_opt).astype(int))\n",
    "prior_match = 1 - ( param['n_expected_matches'] / len(include_these_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Bayes analysis\n",
    "thrs_opt = np.quantile(total_score[include_these_pairs_idx.astype(bool)], prior_match)\n",
    "candidate_pairs = total_score > thrs_opt\n",
    "\n",
    "prior_match = 1 - (param['n_expected_matches'] / param['n_units']**2 ) #Can change value of priors \n",
    "Priors = np.array((prior_match, 1-prior_match))\n",
    "\n",
    "labels = candidate_pairs.astype(int)\n",
    "cond = np.unique(labels)\n",
    "score_vector = param['score_vector']\n",
    "parameter_kernels = np.full((len(score_vector), len(scores_to_include), len(cond)), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bayes analysis\n",
    "parameter_kernels = bf.get_parameter_kernels(scores_to_include, labels, cond, param, add_one = 1)\n",
    "\n",
    "probability = bf.apply_naive_bayes(parameter_kernels, Priors, predictors, param, cond)\n",
    "\n",
    "output_prob_matrix = probability[:,1].reshape(param['n_units'],param['n_units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional function to summarise the output\n",
    "match_threshold = param['match_threshold']\n",
    "#match_threshold = try different values here!\n",
    "\n",
    "util.evaluate_output(output_prob_matrix, param, within_session, session_switch, match_threshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a match threshold and look at the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_threshold = param['match_threshold']\n",
    "#match_threshold = try different values here!\n",
    "output_threshold = np.zeros_like(output_prob_matrix)\n",
    "output_threshold[output_prob_matrix > match_threshold] = 1\n",
    "\n",
    "plt.imshow(output_threshold, cmap = 'Greys')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate data and send data to the GUI\n",
    "gui.process_info_for_GUI(output_prob_matrix, match_threshold, scores_to_include, total_score, amplitude, spatial_decay,\n",
    "                         avg_centroid, avg_waveform, avg_waveform_per_tp, good_wave_idxs, max_site, max_site_mean, \n",
    "                         waveform, within_session, channel_pos, clus_info, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the GUI\n",
    "look at GUI_Reference_Guide.md for infomation on how to effectivley use the GUI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MatchesGUI is a list of 2 sets of matches for both CV \n",
    "#each array is symmetric e.g will have (x,y) and (y,x) as a match\n",
    "is_match, not_match, matches_GUI = gui.run_GUI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all idx pairs where the probability is above the threshold\n",
    "matches_within_session = np.argwhere(output_threshold == 1) #include within session matches\n",
    "matches = np.argwhere( ((output_threshold * within_session)) == True) #exclude within session matches\n",
    "\n",
    "#this function has 2 mode 'and' 'or', which returns a matches if they appear in both or one cv pair\n",
    "#then it will add all the matches selected as IsMaatch, then remove all matches in NotMatch\n",
    "matches_curated = util.curate_matches(matches_GUI, is_match, not_match, mode = 'and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIDs = aid.assign_unique_id(output_prob_matrix, param, clus_info)\n",
    "\n",
    "save_dir = r'Path/to/save/directory'\n",
    "#NOTE - change to matches to matches_curated if done manual curation with the GUI\n",
    "su.save_to_output(save_dir, scores_to_include, matches # matches_curated\n",
    "                  , output_prob_matrix, avg_centroid, avg_waveform, avg_waveform_per_tp, max_site,\n",
    "                   total_score, output_threshold, clus_info, param, UIDs = UIDs, matches_curated = None, save_match_table = True)\n",
    "#save separate CV output, option to save data so cross verification pairs are split up\n",
    "#su.save_to_output_seperate_CV(save_dir, scores_to_include, matches, output_prob_matrix, avg_centroid, avg_waveform, avg_waveform_per_tp, max_site,\n",
    "#                   total_score, output_threshold, clus_info, param, UIDs = UIDs, matches_curated = None, save_match_table = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UMPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
