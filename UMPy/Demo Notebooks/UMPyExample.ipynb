{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This demo notebook, is a detailed guide throught the Unit Match pipeline.\n",
    "\n",
    "This notebook is only recomened if you want more detailed look at Unit Match, or have unconventional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path[0] = str(Path(sys.path[0]).parent)\n",
    "\n",
    "import Param_fun as pf\n",
    "import Metrics_fun as mf\n",
    "import Bayes_fun as bf\n",
    "import utils as util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import GUI as gui\n",
    "import Save_utils as su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in necessary data, individually \n",
    "(Not recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can supply paths to files directly, but reccomended to use the paths_fromKS function below\n",
    "#get default parameters, can add your own before or after!\n",
    "param = util.get_default_param()\n",
    "\n",
    "#Load in the data\n",
    "#The channel position i.e location of active channels\n",
    "ChannelPos1 = np.load(r'Path\\to\\channel_positions.npy')\n",
    "#This makes position 3-D by inserting an axis of all one's in the first axis, to allow easy extension to 3-D coords\n",
    "ChannelPos1 = np.insert(ChannelPos1,0, np.ones(ChannelPos1.shape[0]), axis =1)\n",
    "\n",
    "#path to the average waveforms for each session\n",
    "WavePath1 = r'Path\\to\\RawWaveforms'\n",
    "WavePath2 = r'Path\\to\\RawWaveforms'\n",
    "\n",
    "#path to a tsv file, where the second column contains 'good' for all units you want to include\n",
    "UnitLabelPath1 = r'Path\\to\\cluster_group.tsv'\n",
    "UnitLabelPath2 = r'Path\\to\\cluster_group.tsv'\n",
    "\n",
    "# need to put paths as a list\n",
    "WavePaths = [WavePath1 , WavePath2]\n",
    "UnitLabelPaths = [UnitLabelPath1, UnitLabelPath2]\n",
    "ChannelPos = [ChannelPos1, ChannelPos1] # Want it per session, however usually will be the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from a KiloSort directory\n",
    "This directory needs to have a channel_positoins.npy, cluster_group.tsv and a RawWaveforms folder per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get default parameters, can add your own before or after!\n",
    "param = util.get_default_param()\n",
    "\n",
    "#Give the paths to the KS directories for each session (with a file 'RawWaveforms' )\n",
    "KSdirs = [r'path/to/KSdir/Session1', r'Path/to/KSdir/Session2']\n",
    "WavePaths, UnitLabelPaths, ChannelPos = util.paths_fromKS(KSdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data and select the good units and exact metadata\n",
    "\n",
    "GoodUnits = util.get_good_units(UnitLabelPaths, good = True ) # good = False to load in ALL units\n",
    "waveform, SessionID, SessionSwitch, WithinSession, param = util.load_good_units(GoodUnits, WavePaths, param)\n",
    "\n",
    "#waveform, SessionID, SessionSwitch, WithinSession, GoodUnits, param = util.load_good_waveforms(WavePaths, UnitLabelPaths, param) # 1-step version of above\n",
    "\n",
    "# create clusInfo, contains all unit id/session related info\n",
    "ClusInfo = {'GoodUnits' : GoodUnits, 'SessionSwitch' : SessionSwitch, 'SessionID' : SessionID, \n",
    "            'OriginalID' : np.concatenate(GoodUnits) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Unit Match process\n",
    "1. Extract parameters from the waveforms e.g Amplitudes, weighted average waveforms and Spatial Decay lengths\n",
    "2. Calculate metrics/scores for matching e.g Amplitude Score and Waveform similarity\n",
    "3. Using putative matches find a estimate of drit correction between session (canbe done per shank for 2.0 probes)\n",
    "4. Re-Calculate metrics/scores with the drift corrected metrics\n",
    "5. Use a naive Bayes classifier to get suggested 'matches' and 'non'matches'\n",
    "6. (Optionall) run the GUIto currated the suggest matches and investigated the UnitMatch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get parameters from the wavefunction\n",
    "\n",
    "waveform = pf.detrend_waveform(waveform)\n",
    "\n",
    "MaxSite, goodidx, goodpos, MaxSiteMean = pf.get_max_sites(waveform, ChannelPos,ClusInfo, param)\n",
    "\n",
    "SpatialDecayFit , SpatialDecay,  d_10, AvgCentroid, AvgWaveform, PeakTime = pf.decay_and_average_Waveform(waveform,ChannelPos, goodidx, MaxSite, MaxSiteMean, ClusInfo, param)\n",
    "\n",
    "Amplitude, waveform, AvgWaveform = pf.get_amplitude_shift_Waveform(waveform,AvgWaveform, PeakTime, param)\n",
    "\n",
    "WaveformDuration, AvgWaveformPerTP, WaveIdx = pf.avg_Waveform_PerTP(waveform,ChannelPos, d_10, MaxSiteMean, Amplitude, AvgWaveform, ClusInfo, param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Metrics/Scores from the extracted parameters\n",
    "\n",
    "AmpScore = mf.get_simple_metric(Amplitude)\n",
    "SpatialDecayScore = mf.get_simple_metric(SpatialDecay)\n",
    "SpatialDecayFitScore = mf.get_simple_metric(SpatialDecayFit, outlier = True)\n",
    "WVcorrScore = mf.get_WVcorr(AvgWaveform, param)\n",
    "WFMSEscore = mf.get_WaveformMSE(AvgWaveform, param)\n",
    "\n",
    "AvgWaveformPerTPFlip = mf.flip_dim(AvgWaveformPerTP, param)\n",
    "EuclDist = mf.get_Euclidean_dist(AvgWaveformPerTPFlip,param)\n",
    "\n",
    "CentroidDist, CentroidVar = mf.Centroid_metrics(EuclDist, param)\n",
    "\n",
    "EuclDistRC = mf.get_recentered_Euclidean_dist(AvgWaveformPerTPFlip, AvgCentroid, param)\n",
    "\n",
    "CentroidDistRecentered = mf.recentered_metrics(EuclDistRC)\n",
    "TrajAngleScore, TrajDistScore = mf.dist_angle(AvgWaveformPerTPFlip, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collate themetrics and find the putative matches\n",
    "# Average Euc Dist\n",
    "EuclDist = np.nanmin(EuclDist[:,param['PeakLoc'] - param['waveidx'] == 0, :,:].squeeze(), axis = 1 )\n",
    "\n",
    "# TotalScore\n",
    "IncludeThesePairs = np.argwhere( EuclDist < param['MaxDist']) #array indices of pairs to include\n",
    "\n",
    "# Make a dictionary of score to include\n",
    "CentroidOverlordScore = (CentroidDistRecentered + CentroidVar) / 2\n",
    "WaveformScore = (WVcorrScore + WFMSEscore) / 2\n",
    "TrajectoryScore = (TrajAngleScore + TrajDistScore) / 2\n",
    "\n",
    "Scores2Include = {'AmpScore' : AmpScore, 'SpatialDecayScore' : SpatialDecayScore, 'CentroidOverlord' : CentroidOverlordScore,\n",
    "                  'CentroidDist' : CentroidDist, 'WaveformScore' : WaveformScore, 'TrajectoryScore': TrajectoryScore }\n",
    "\n",
    "TotalScore, Predictors = mf.get_total_score(Scores2Include, param)\n",
    "\n",
    "#Initial thresholding\n",
    "\n",
    "ThrsOpt = mf.get_threshold(TotalScore, WithinSession, EuclDist, param, IsFirstPass = True)\n",
    "\n",
    "param['nExpectedMatches'] = np.sum( (TotalScore > ThrsOpt).astype(int))\n",
    "priorMatch = 1 - ( param['nExpectedMatches'] / len(IncludeThesePairs))\n",
    "CandidatePairs = TotalScore > ThrsOpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drift\n",
    "drifts, AvgCentroid, AvgWaveformPerTP = mf.drift_nSessions(CandidatePairs, SessionSwitch, AvgCentroid, AvgWaveformPerTP, TotalScore, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-do metric extraction with the drift corrected arrays\n",
    "\n",
    "AvgWaveformPerTPFlip = mf.flip_dim(AvgWaveformPerTP, param)\n",
    "EuclDist = mf.get_Euclidean_dist(AvgWaveformPerTPFlip,param)\n",
    "\n",
    "CentroidDist, CentroidVar = mf.Centroid_metrics(EuclDist, param)\n",
    "\n",
    "EuclDistRC = mf.get_recentered_Euclidean_dist(AvgWaveformPerTPFlip, AvgCentroid, param)\n",
    "\n",
    "CentroidDistRecentered = mf.recentered_metrics(EuclDistRC)\n",
    "TrajAngleScore, TrajDistScore = mf.dist_angle(AvgWaveformPerTPFlip, param)\n",
    "\n",
    "# Average Euc Dist\n",
    "EuclDist = np.nanmin(EuclDist[:,param['PeakLoc'] - param['waveidx'] == 0, :,:].squeeze(), axis = 1 )\n",
    "\n",
    "# TotalScore\n",
    "IncludeThesePairs = np.argwhere( EuclDist < param['MaxDist']) #array indices of pairs to include, in ML its IncludeThesePairs[:,1]\n",
    "IncludeThesePairs_idx = np.zeros_like(TotalScore)\n",
    "IncludeThesePairs_idx[EuclDist < param['MaxDist']] = 1 \n",
    "\n",
    "# Make a dictionary of score to include\n",
    "CentroidOverlordScore = (CentroidDistRecentered + CentroidVar) / 2\n",
    "WaveformScore = (WVcorrScore + WFMSEscore) / 2\n",
    "TrajectoryScore = (TrajAngleScore + TrajDistScore) / 2\n",
    "\n",
    "Scores2Include = {'AmpScore' : AmpScore, 'SpatialDecayScore' : SpatialDecayScore, 'CentroidOverlord' : CentroidOverlordScore,\n",
    "                  'CentroidDist' : CentroidDist, 'WaveformScore' : WaveformScore, 'TrajectoryScore': TrajectoryScore }\n",
    "\n",
    "TotalScore, Predictors = mf.get_total_score(Scores2Include, param)\n",
    "ThrsOpt = mf.get_threshold(TotalScore, WithinSession, EuclDist, param, IsFirstPass = False)\n",
    "\n",
    "\n",
    "param['nExpectedMatches'] = np.sum( (TotalScore > ThrsOpt).astype(int))\n",
    "priorMatch = 1 - ( param['nExpectedMatches'] / len(IncludeThesePairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Bayes analysis\n",
    "ThrsOpt = np.quantile(TotalScore[IncludeThesePairs_idx.astype(bool)], priorMatch)\n",
    "CandidatePairs = TotalScore > ThrsOpt\n",
    "\n",
    "priorMatch = 1 - (param['nExpectedMatches'] / param['nUnits']**2 ) #Can change value of priors \n",
    "Priors = np.array((priorMatch, 1-priorMatch))\n",
    "\n",
    "labels = CandidatePairs.astype(int)\n",
    "Cond = np.unique(labels)\n",
    "ScoreVector = param['ScoreVector']\n",
    "ParameterKernels = np.full((len(ScoreVector), len(Scores2Include), len(Cond)), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bayes analysis\n",
    "ParameterKernels = bf.get_ParameterKernels(Scores2Include, labels, Cond, param, addone = 1)\n",
    "\n",
    "Probability = bf.apply_naive_bayes(ParameterKernels, Priors, Predictors, param, Cond)\n",
    "\n",
    "Output = Probability[:,1].reshape(param['nUnits'],param['nUnits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional function tosummarise the output\n",
    "util.evaluate_output(Output, param, WithinSession, SessionSwitch, MatchThreshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a match threshold and look at the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatchThreshold = param['MatchThreshold']\n",
    "#MatchThreshold = try different values here!\n",
    "OutputThreshold = np.zeros_like(Output)\n",
    "OutputThreshold[Output > MatchThreshold] = 1\n",
    "\n",
    "plt.imshow(OutputThreshold, cmap = 'grays')\n",
    "#plt.imshow(Output)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte data and send data to the GUI\n",
    "gui.process_info_for_GUI(Output, MatchThreshold, Scores2Include, TotalScore, Amplitude, SpatialDecay,\n",
    "                         AvgCentroid, AvgWaveform, AvgWaveformPerTP, WaveIdx, MaxSite, MaxSiteMean, \n",
    "                         waveform, WithinSession, ChannelPos, ClusInfo, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the GUI\n",
    "look at GUI_Reference_Guide.md for infomation on how to effectivley use the GUI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MatchesGUI is a list of 2 sets of matches for both CV \n",
    "#each array is symetric e.g will have (x,y) and (y,x) as a match\n",
    "IsMatch, NotMatch, MatchesGUI = gui.run_GUI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all idx pairs where the proabilty is above the threshold\n",
    "Matches = np.argwhere(OutputThreshold == 1) #include within session matches\n",
    "matches = np.argwhere( ((OutputThreshold * WithinSession)) == True) #exclude within session macthes\n",
    "\n",
    "#this function has 2 mode 'And' 'Or', which returns a matches if they appear in both or one cv pair\n",
    "#then it will add all the matches selected as IsMaatch, then remove all matches in NotMatch\n",
    "MatchesCurrated = util.currate_matches(MatchesGUI, IsMatch, NotMatch, Mode = 'And')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveDir = r'Path\\to\\Save\\directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save base output\n",
    "su.save_to_output(SaveDir, Scores2Include, Matches, Output, AvgCentroid, AvgWaveform, AvgWaveformPerTP, MaxSite, TotalScore, OutputThreshold, ClusInfo, param, MatchesCurated = None, SaveMatchTable = True)\n",
    "\n",
    "#save seperate CV output, option to save data so cross verification pairs are split up\n",
    "#su.save_to_output_seperate_CV(SaveDir, Scores2Include, Matches, Output, AvgCentroid, AvgWaveform, AvgWaveformPerTP, MaxSite,\n",
    "#                   TotalScore, MatchThreshold, ClusInfo, param, MatchesCurated = None, SaveMatchTable = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
